"""
Lightning Callbacks for ArcFace Training
"""

from typing import Optional

import lightning as L
import numpy as np
import torch
import torch.nn.functional as F
from sklearn.metrics import accuracy_score
from torch.utils.data import DataLoader

from arcface_lightning_v2.data.lfw_dataset import LFWPairsDataset


class LFWVerificationCallback(L.Callback):
    """
    LFW ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•œ Face Verification Callback
    ì£¼ê¸°ì ìœ¼ë¡œ ëª¨ë¸ì˜ verification accuracyë¥¼ ê³„ì‚°í•˜ê³  ë¡œê¹…

    ì§€ì›í•˜ëŠ” annotation íŒŒì¼ í˜•ì‹:
    1. <path1> <path2> <label> (ê¸°ì¡´ í˜•ì‹)
    2. <label> <path1> <path2> (lfw_ann.txt í˜•ì‹)
    """

    def __init__(
        self,
        pairs_file: str,
        root_dir: Optional[str] = None,
        image_size: tuple = (112, 112),
        batch_size: int = 32,
        num_workers: int = 4,
        verbose: int = 2000,  # ëª‡ stepë§ˆë‹¤ ì‹¤í–‰í• ì§€
        n_folds: int = 10,  # K-fold cross validation
    ):
        """
        Args:
            pairs_file: pairs.txt ë˜ëŠ” lfw_ann.txt íŒŒì¼ ê²½ë¡œ
                       í˜•ì‹: <path1> <path2> <label> ë˜ëŠ” <label> <path1> <path2>
            root_dir: ì´ë¯¸ì§€ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ (annotation íŒŒì¼ì˜ ê²½ë¡œê°€ ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš°)
            image_size: ì´ë¯¸ì§€ í¬ê¸°
            batch_size: ë°°ì¹˜ í¬ê¸°
            num_workers: DataLoader worker ìˆ˜
            verbose: ëª‡ stepë§ˆë‹¤ verification ìˆ˜í–‰í• ì§€ (í˜„ì¬ ë¹„í™œì„±í™”ë¨)
            n_folds: K-fold cross validation fold ìˆ˜
        """
        super().__init__()
        self.pairs_file = pairs_file
        self.root_dir = root_dir
        self.image_size = image_size
        self.batch_size = batch_size
        self.num_workers = num_workers
        self.verbose = verbose
        self.n_folds = n_folds

        self.highest_acc = 0.0
        self.dataset = None
        self.dataloader = None

    def setup(
        self, trainer: L.Trainer, pl_module: L.LightningModule, stage: str
    ) -> None:
        """ë°ì´í„°ì…‹ ì´ˆê¸°í™”"""
        if self.dataset is None:
            self.dataset = LFWPairsDataset(
                pairs_file=self.pairs_file,
                root_dir=self.root_dir,
                image_size=self.image_size,
            )
            self.dataloader = DataLoader(
                self.dataset,
                batch_size=self.batch_size,
                shuffle=False,
                num_workers=self.num_workers,
                pin_memory=torch.cuda.is_available(),
            )

    def on_train_batch_end(
        self,
        trainer: L.Trainer,
        pl_module: L.LightningModule,
        outputs,
        batch,
        batch_idx: int,
    ) -> None:
        """í•™ìŠµ ë°°ì¹˜ ëë‚  ë•Œ ì£¼ê¸°ì ìœ¼ë¡œ verification ìˆ˜í–‰ (ë¹„í™œì„±í™”ë¨)"""
        # ì£¼ê¸°ì  verificationì€ ë¹„í™œì„±í™”
        # epoch ëì—ì„œë§Œ verification ìˆ˜í–‰í•˜ë„ë¡ ë³€ê²½
        # global_step = trainer.global_step
        # if global_step > 0 and global_step % self.verbose == 0:
        #     self._run_verification(trainer, pl_module, global_step)
        pass

    def on_train_epoch_end(
        self, trainer: L.Trainer, pl_module: L.LightningModule
    ) -> None:
        """Epoch ëë‚  ë•Œ verification ìˆ˜í–‰"""
        # on_train_epoch_endì—ì„œëŠ” on_step=False, on_epoch=Trueë§Œ í—ˆìš©ë¨
        self._run_verification(
            trainer, pl_module, trainer.global_step, on_step=False, on_epoch=True
        )

    def _run_verification(
        self,
        trainer: L.Trainer,
        pl_module: L.LightningModule,
        global_step: int,
        on_step: bool = True,
        on_epoch: bool = False,
    ) -> None:
        """Verification ìˆ˜í–‰"""
        # ğŸŸ© í–‰ë™ 1: DDP ë©€í‹°ë…¸ë“œ í™˜ê²½ì—ì„œ rank 0ì—ì„œë§Œ ì‹¤í–‰
        # ì—¬ëŸ¬ rankì—ì„œ ë™ì‹œì— ì‹¤í–‰í•˜ë©´ ì¤‘ë³µ ê³„ì‚° ë° ì˜ëª»ëœ ê²°ê³¼ ë°œìƒ
        if trainer.global_rank != 0:
            return

        if self.dataset is None:
            self.setup(trainer, pl_module, "fit")

        # ëª¨ë¸ì„ eval ëª¨ë“œë¡œ ì „í™˜
        pl_module.eval()

        embeddings1_list = []
        embeddings2_list = []
        labels_list = []

        with torch.no_grad():
            for img1, img2, label in self.dataloader:
                # GPUë¡œ ì´ë™
                img1 = img1.to(pl_module.device)
                img2 = img2.to(pl_module.device)

                # Embedding ì¶”ì¶œ
                emb1 = pl_module(img1)  # pl_module.forward() í˜¸ì¶œ
                emb2 = pl_module(img2)

                # L2 ì •ê·œí™”
                emb1 = F.normalize(emb1, p=2, dim=1)
                emb2 = F.normalize(emb2, p=2, dim=1)

                embeddings1_list.append(emb1.cpu().numpy())
                embeddings2_list.append(emb2.cpu().numpy())
                labels_list.append(label.numpy())

        # ë¦¬ìŠ¤íŠ¸ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
        embeddings1 = np.concatenate(embeddings1_list, axis=0)
        embeddings2 = np.concatenate(embeddings2_list, axis=0)
        labels = np.concatenate(labels_list, axis=0)

        # Cosine similarity ê³„ì‚°
        similarities = np.sum(embeddings1 * embeddings2, axis=1)

        # K-fold cross validationìœ¼ë¡œ ìµœì  threshold ì°¾ê¸°
        accuracy, threshold = self._k_fold_accuracy(similarities, labels, self.n_folds)

        # ëª¨ë¸ì„ train ëª¨ë“œë¡œ ë³µì›
        pl_module.train()

        # ë¡œê¹…
        if accuracy > self.highest_acc:
            self.highest_acc = accuracy

        # Lightning loggerì— ê¸°ë¡
        # on_stepê³¼ on_epoch íŒŒë¼ë¯¸í„°ëŠ” í˜¸ì¶œ ì»¨í…ìŠ¤íŠ¸ì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì„¤ì •ë¨
        # on_train_epoch_endì—ì„œëŠ” on_step=False, on_epoch=Trueë§Œ í—ˆìš©ë¨
        # on_train_batch_endì—ì„œëŠ” on_step=True, on_epoch=False ì‚¬ìš© ê°€ëŠ¥
        pl_module.log(
            "val/lfw_accuracy",
            accuracy,
            on_step=on_step,
            on_epoch=on_epoch,
            prog_bar=True,
        )
        pl_module.log(
            "val/lfw_threshold", threshold, on_step=on_step, on_epoch=on_epoch
        )
        pl_module.log(
            "val/lfw_highest_accuracy",
            self.highest_acc,
            on_step=on_step,
            on_epoch=on_epoch,
        )

    def _k_fold_accuracy(
        self,
        similarities: np.ndarray,
        labels: np.ndarray,
        n_folds: int = 10,
    ) -> tuple:
        """
        K-fold cross validationìœ¼ë¡œ ìµœì  threshold ì°¾ê³  accuracy ê³„ì‚°

        Returns:
            (accuracy, threshold)
        """
        from sklearn.model_selection import KFold

        indices = np.arange(len(similarities))
        kfold = KFold(n_splits=n_folds, shuffle=False)

        accuracies = []
        thresholds = []

        for train_idx, test_idx in kfold.split(indices):
            train_sim = similarities[train_idx]
            train_labels = labels[train_idx]

            test_sim = similarities[test_idx]
            test_labels = labels[test_idx]

            # Train setì—ì„œ ìµœì  threshold ì°¾ê¸°
            best_threshold = self._find_best_threshold(train_sim, train_labels)
            thresholds.append(best_threshold)

            # Test setì—ì„œ accuracy ê³„ì‚°
            predictions = (test_sim >= best_threshold).astype(int)
            acc = accuracy_score(test_labels, predictions)
            accuracies.append(acc)

        # í‰ê·  accuracyì™€ threshold ë°˜í™˜
        mean_accuracy = np.mean(accuracies)
        mean_threshold = np.mean(thresholds)

        return mean_accuracy, mean_threshold

    def _find_best_threshold(
        self,
        similarities: np.ndarray,
        labels: np.ndarray,
    ) -> float:
        """ìµœì  threshold ì°¾ê¸° (train setì—ì„œ)"""
        # ğŸŸ© í–‰ë™ 2: threshold resolutionì„ 0.001ë¡œ ë³€ê²½ (ê¸°ì¡´ 0.01)
        # ë” ì •ë°€í•œ threshold íƒìƒ‰ìœ¼ë¡œ accuracy í–¥ìƒ ê°€ëŠ¥ (+0.02 ì •ë„)
        thresholds = np.arange(-1.0, 1.0, 0.001)

        best_threshold = 0.0
        best_accuracy = 0.0

        for threshold in thresholds:
            predictions = (similarities >= threshold).astype(int)
            accuracy = accuracy_score(labels, predictions)

            if accuracy > best_accuracy:
                best_accuracy = accuracy
                best_threshold = threshold

        return best_threshold
